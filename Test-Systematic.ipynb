{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4BUqOfSw9hjX"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from math import tan, atan, radians, degrees\n","import random\n","import json\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YAotA6l9qeP"},"outputs":[],"source":["drive.mount('/content/drive')\n","%cd /write/your/directory/to/AI_4_ATD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_pSFKR0LWyD"},"outputs":[],"source":["epsilon = 0.001"]},{"cell_type":"markdown","metadata":{"id":"SmeBu_679-ul"},"source":["# Define Processing Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hO3xZ3Po_gx9"},"outputs":[],"source":["class Format():\n","  def __init__(self):\n","    self.scale = 0\n","    self.cns = 0\n","    self.ia = 0\n","    self.imp = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3_Q3CJ7_jZa"},"outputs":[],"source":["def SCALE(dataset, labels, format):\n","  batch, n_lines, n_points = dataset.shape\n","  for i in range(batch):\n","    max_val = np.max(np.absolute([y for y in dataset[i][0]]))\n","    for j in range(n_lines - 1):\n","      new_max_val = np.max(np.absolute([y for y in dataset[i][j + 1]]))\n","      if new_max_val > max_val:\n","        max_val = new_max_val\n","    for j in range(n_lines):\n","      for k in range(n_points):\n","        if dataset[i][j][k] != -1:\n","          dataset[i][j][k] /= max_val\n","  format.scale = 1\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkmtFxo2h-zo"},"outputs":[],"source":["def SCALE(dataset, labels, format):\n","  shape = dataset.shape\n","  if len(shape) == 3:\n","    batch, n_lines, n_points = shape\n","    for i in range(batch):\n","      max_val = np.max(np.absolute([y for y in dataset[i][0]]))\n","      for j in range(n_lines - 1):\n","        new_max_val = np.max(np.absolute([y for y in dataset[i][j + 1]]))\n","        if new_max_val > max_val:\n","          max_val = new_max_val\n","      for j in range(n_lines):\n","        for k in range(n_points):\n","          if dataset[i][j][k] != -1:\n","            dataset[i][j][k] /= max_val\n","  else:\n","    batch, n_points = shape\n","    for i in range(batch):\n","      max_val = np.max(np.absolute([y for y in dataset[i]]))\n","      for j in range(n_points):\n","        if dataset[i][j] != -1:\n","          dataset[i][j] /= max_val\n","  format.scale = 1\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rx062tm0_ksj"},"outputs":[],"source":["def CNS(dataset, labels, format):\n","  batch, n_lines, n_points = dataset.shape\n","  for i in range(batch):\n","    c_mean = np.mean([y for y in dataset[i][0] if y != -1])\n","    c_std = np.std([y for y in dataset[i][0] if y != -1]).clip(epsilon, None)\n","    for j in range(n_lines):\n","      for k in range(n_points):\n","        if dataset[i][j][k] != -1:\n","          dataset[i][j][k] = (dataset[i][j][k] - c_mean) / c_std\n","  dataset = np.delete(dataset, 0, axis=1)\n","\n","  format.cns = 1\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gs35BXdO_mZF"},"outputs":[],"source":["def IA(dataset, labels, format):\n","\n","  if format.cns == 0:\n","    control = dataset[:, 0, :].copy()\n","    dataset = np.delete(dataset, 0, axis=1)\n","\n","  batch, n_lines, n_points = dataset.shape\n","  dataset = (dataset.copy()).reshape(batch*n_lines, n_points)\n","\n","  if format.cns == 0:\n","    control = np.repeat(control, repeats=3, axis=0)\n","    dataset = np.stack((control, dataset), axis=1)\n","\n","  labels = labels.reshape(batch*n_lines)\n","\n","  format.ia = 1\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJOoQVJR_plh"},"outputs":[],"source":["def iqm(series, q):\n","  q1 = np.quantile(series, 1-q)\n","  q3 = np.quantile(series, q)\n","  series = [y for y in series if q1 <= y <= q3]\n","  return np.mean(series)\n","\n","def imputate(dataset, labels, format, imp_type):\n","  shape = dataset.shape\n","  if len(shape) == 3:\n","    batch, n_series, n_points = shape\n","    for i in range(batch):\n","      for j in range(n_series):\n","        series = [y for y in dataset[i][j] if y != -1]\n","        if len(series) == 0:\n","          dataset[i][j] = np.zeros(n_points)\n","        elif imp_type == 'mean':\n","          imput_val = np.mean(series)\n","        elif imp_type == 'median':\n","          imput_val = np.median(series)\n","        elif imp_type == 'iqm':\n","          imput_val = iqm(series, 0.75)\n","        else:\n","          assert False, f\"imp_type={imp_type}\"\n","\n","        for k in range(n_points):\n","          if dataset[i][j][k] == -1:\n","            dataset[i][j][k] = imput_val\n","  else:\n","    batch, n_points = shape\n","    for i in range(batch):\n","      series = [y for y in dataset[i] if y != -1]\n","      if len(series) == 0:\n","        dataset[i] = np.zeros(n_points)\n","      elif imp_type == 'mean':\n","        imput_val = np.mean(series)\n","      elif imp_type == 'median':\n","        imput_val = np.median(series)\n","      elif imp_type == 'iqm':\n","        imput_val = iqm(series, 0.75)\n","      else:\n","        assert False, f\"imp_type={imp_type}\"\n","\n","      for j in range(n_points):\n","          if dataset[i][j] == -1:\n","            dataset[i][j] = imput_val\n","  if imp_type == 'mean':\n","    format.imp = 1\n","  elif imp_type == 'median':\n","    format.imp = 2\n","  elif imp_type == 'iqm':\n","    format.imp = 3\n","  else:\n","    assert False, f\"imp_type={imp_type}\"\n","\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vi9Mg2-B_7Kg"},"outputs":[],"source":["def process(dataset, labels, goal_format):\n","  format = Format()\n","  if goal_format.cns == 1:\n","    dataset, labels, format = CNS(dataset, labels, format)\n","  if goal_format.ia == 1:\n","    dataset, labels, format = IA(dataset, labels, format)\n","  if goal_format.imp == 1:\n","    dataset, labels, format = imputate(dataset, labels, format, 'mean')\n","  elif goal_format.imp == 2:\n","    dataset, labels, format = imputate(dataset, labels, format, 'median')\n","  elif goal_format.imp == 3:\n","    dataset, labels, format = imputate(dataset, labels, format, 'iqm')\n","  if goal_format.scale == 1:\n","    dataset, labels, format = SCALE(dataset, labels, format)\n","\n","  assert format.cns == goal_format.cns\n","  assert format.scale == goal_format.scale\n","  assert format.ia == goal_format.ia\n","  assert format.imp == goal_format.imp\n","\n","  return dataset, labels, format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sqzl0eYumI99"},"outputs":[],"source":["def build_model(format):\n","  # Determine the output size and input shape based on the format's 'ia' and 'cns' flags\n","  if format.ia == 0:\n","    out_size = 3\n","    if format.cns == 0:\n","      input_shape = (4, 10)\n","    else:\n","      input_shape = (3, 10)\n","  else:\n","    out_size = 1\n","    if format.cns == 0:\n","      input_shape = (2, 10)\n","    else:\n","      input_shape = (10,)\n","\n","  # Initialize a Sequential Keras model\n","  model = tf.keras.Sequential()\n","  # Flatten the input data to a 1D vector\n","  model.add(layers.Flatten(input_shape=input_shape))\n","  # Add dense layers with ReLU activation for feature extraction\n","  model.add(layers.Dense(16, activation='relu'))\n","  model.add(layers.Dense(16, activation='relu'))\n","  # Add a Dropout layer to prevent overfitting\n","  model.add(layers.Dropout(0.2))\n","  # Add the output dense layer with softmax activation for classification\n","  model.add(layers.Dense(2*out_size, activation='softmax'))\n","  # Reshape the output if the original output size was 3, then apply softmax again\n","  if out_size == 3:\n","    model.add(layers.Reshape((3, 2)))\n","    model.add(layers.Softmax(axis=2))\n","  # Otherwise, apply softmax directly to the output\n","  else:\n","    model.add(layers.Softmax())\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"piuTfIWm9ghD"},"source":["# Define Model Testing Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9fTBC7m9ghF"},"outputs":[],"source":["class Metrics():\n","  # Class to store various performance metrics for a model\n","  def __init__(self):\n","    self.acc = 0.0\n","    self.precision = 0.0\n","    self.recall = 0.0\n","    self.f1 = 0.0\n","    self.power = 0.0\n","    self.type1 = 0.0\n","    self.metrics_by_power = {}\n","\n","def calc_metrics(preds, labels):\n","  # Calculates fundamental classification metrics (accuracy, precision, recall, f1, power, type1)\n","  true = preds == labels\n","  TP = np.sum(true * labels)\n","  TN = np.sum(true * (1 - labels))\n","  FP = np.sum((1 - true) * (1 - labels))\n","  FN = np.sum((1 - true) * labels)\n","  acc = (TP + TN) / (TP + TN + FP + FN)\n","  precision = TP / (TP + FP)\n","  recall = TP / (TP + FN)\n","  f1 = 2 * precision * recall / (precision + recall)\n","  power = TP / (TP + FN)\n","  type1 = FP / (FP + TN)\n","\n","  return acc, precision, recall, f1, power, type1\n","\n","def calc_metrics_by_power(preds, labels, effect_sizes, bin_values):\n","  # Calculates performance metrics binned by effect size categories\n","  metrics_by_power = {}\n","  n = len(bin_values)\n","  diff_mask = labels != 0\n","\n","  # Get metrics for undifferentiated conditions (labels == 0)\n","  metrics = {}\n","  undiff_mask = labels == 0\n","  bin_preds = preds[undiff_mask]\n","  bin_labels = labels[undiff_mask]\n","  acc, precision, recall, f1, power, type1 = calc_metrics(bin_preds, bin_labels)\n","  metrics['acc'] = acc\n","  metrics['precision'] = precision\n","  metrics['recall'] = recall\n","  metrics['f1'] = f1\n","  metrics['power'] = power\n","  metrics['type1'] = type1\n","  metrics['n'] = len(bin_preds)\n","  metrics_by_power['undiff'] = metrics\n","\n","  # Get metrics for each defined effect size bin\n","  for i in range(n):\n","    metrics = {}\n","    if i == n-1:\n","      # For the last bin, include all effect sizes greater than or equal to the last bin value\n","      mask = ( (effect_sizes >= bin_values[i]) | (effect_sizes == -2) ) & diff_mask\n","    else:\n","      # For other bins, define a range [bin_value_i, bin_value_{i+1})\n","      mask = (bin_values[i] <= effect_sizes) & (bin_values[i+1] > effect_sizes) & diff_mask\n","    mask = mask.flatten()\n","    bin_preds = preds[mask]\n","    bin_labels = labels[mask]\n","    bin_effect_sizes = effect_sizes[mask]\n","    acc, precision, recall, f1, power, type1 = calc_metrics(bin_preds, bin_labels)\n","    metrics['acc'] = acc\n","    metrics['precision'] = precision\n","    metrics['recall'] = recall\n","    metrics['f1'] = f1\n","    metrics['power'] = power\n","    metrics['type1'] = type1\n","    metrics['n'] = len(bin_preds)\n","    metrics_by_power[bin_values[i]] = metrics\n","\n","  return metrics_by_power\n","\n","\n","def compute_metrics(model, data, lbls, effect_sizes):\n","  # Computes and aggregates various performance metrics for a given model\n","  effect_sizes = effect_sizes.flatten()\n","  mask = effect_sizes != -1 # Mask out invalid effect sizes\n","  dataset = data.copy()\n","  labels = lbls.copy()\n","  preds = np.argmax(model.predict(dataset, verbose=0), axis=-1) # Get model predictions\n","  preds = preds.flatten()\n","  labels = labels.flatten()\n","  preds = preds[mask]\n","  labels = labels[mask]\n","\n","  # Calculate overall metrics\n","  true = preds == labels\n","  TP = np.sum(true * labels)\n","  TN = np.sum(true * (1 - labels))\n","  FP = np.sum((1 - true) * (1 - labels))\n","  FN = np.sum((1 - true) * labels)\n","  acc = (TP + TN) / (TP + TN + FP + FN)\n","  precision = TP / (TP + FP)\n","  recall = TP / (TP + FN)\n","  f1 = 2 * precision * recall / (precision + recall)\n","  power = TP / (TP + FN)\n","  type1 = FP / (FP + TN)\n","\n","  # Define bins for effect sizes and calculate binned metrics\n","  bin_values = [0, 1, 2, 3, 4, 6, 10]\n","  metrics_by_power = calc_metrics_by_power(preds, labels, effect_sizes[mask], bin_values)\n","\n","  # Populate a Metrics object with the calculated values\n","  metrics = Metrics()\n","  metrics.acc = float(acc)\n","  metrics.precision = float(precision)\n","  metrics.recall = float(recall)\n","  metrics.f1 = float(f1)\n","  metrics.power = float(power)\n","  metrics.type1 = float(type1)\n","  metrics.metrics_by_power = metrics_by_power\n","\n","  return metrics\n","\n","def create_ratings(model, data, lbls):\n","  # Generates predictions (ratings) from a given model and dataset\n","  dataset = data.copy()\n","  labels = lbls.copy()\n","  preds = np.argmax(model.predict(dataset, verbose=0), axis=-1) # Get model predictions\n","  preds = preds.flatten()\n","  return preds"]},{"cell_type":"markdown","metadata":{"id":"UIy8QtaG-C6C"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tu8ktzjn-EMk"},"outputs":[],"source":["dataset = np.load('Datasets/real_dataset.npy')\n","labels = np.load('Datasets/real_labels.npy')\n","effect_sizes = np.load('Datasets/real_effect_sizes.npy')"]},{"cell_type":"markdown","metadata":{"id":"UfEESgR_mIhQ"},"source":["## Plot Testing Graph Examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnXeMX1EmL9V"},"outputs":[],"source":["def plot_ATD(ax, graph, label, idx):\n","  random.seed(346)\n","  markers = ['o', 'v', 's', 'x']\n","  legend = ['Control', 'Condition 1', 'Condition 2', 'Condition 3']\n","  for i, line in enumerate(graph):\n","    series = [y for y in line if y != -1]\n","    if len(series) > 0:\n","      ax.plot([y for y in line if y != -1], color='k', marker = markers[i], label=legend[i])\n","  ax.legend()\n","  ax.set_title(f\"(i={idx}), Label={label}\")\n","  ax.set_xlabel('Session')\n","  ax.set_ylabel('Behavior Response')\n","\n","# Generate three random indices\n","random_indices = random.sample(range(len(dataset)), 3)\n","\n","# Create a figure with three subplots\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# Plot each selected graph\n","for i, idx in enumerate(random_indices):\n","  plot_ATD(axes[i], dataset[idx], labels[idx], idx)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hQHFyKPDwRIF"},"source":["# Load Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkq3gC9YwXkp"},"outputs":[],"source":["import re\n","\n","model_runs = [0,1,2,3,4]\n","\n","model_dict = {}\n","first_run = True\n","for run in model_runs:\n","  # Iterate through each model run directory\n","  model_files = [f for f in os.listdir(f'Training_Runs/SYS_Models_Run{run}') if 'FAM-SYS-' in f]\n","  if first_run:\n","    # Extract unique model IDs from filenames during the first run\n","    model_ids = [f[8:12] for f in model_files if 'FAM-SYS-' in f]\n","    first_run = False\n","  for i, id in enumerate(model_ids):\n","    # Initialize a Format object based on the model ID\n","    format = Format()\n","    format.scale = int(id[0])\n","    format.cns = int(id[1])\n","    format.ia = int(id[2])\n","    format.imp = int(id[3])\n","    if id not in model_dict:\n","      # If the model ID is new, create an entry in model_dict\n","      model_dict[id] = {\n","          'models': [],\n","          'epochs': [],\n","          'format': format,\n","          'metrics': {\n","              'acc': [],\n","              'precision': [],\n","              'recall': [],\n","              'f1': [],\n","              'power': [],\n","              'type1': [],\n","              'type2' : [],\n","          }\n","      }\n","    # Load the Keras model and add it to the model_dict\n","    model_dict[id]['models'].append(tf.keras.models.load_model(f'Training_Runs/SYS_Models_Run{run}/{model_files[i]}', safe_mode=False))\n","    # Extract and store the number of training epochs if present in the filename\n","    if 'ep=' in model_files[i]:\n","      epochs = re.search(r'ep=(\\d+)', model_files[i]).group(1)\n","      model_dict[id]['epochs'].append(epochs)"]},{"cell_type":"markdown","metadata":{"id":"mRGp_1w99bcp"},"source":["# Model Testing"]},{"cell_type":"markdown","metadata":{"id":"1oYFSFVsya8z"},"source":["## Aggregate Run Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"UIqa8OCGynol"},"outputs":[],"source":["for id in model_dict:\n","  # Process the dataset and labels according to the current model's format requirements\n","  dataset_it, labels_it, format = process(dataset.copy(), labels, model_dict[id]['format'])\n","  for model in model_dict[id]['models']:\n","    # Compute evaluation metrics for each model using the processed data\n","    metrics = compute_metrics(model, dataset_it, labels_it, effect_sizes)\n","    # Append calculated metrics to the model_dict for later aggregation\n","    model_dict[id]['metrics']['acc'].append(metrics.acc)\n","    model_dict[id]['metrics']['precision'].append(metrics.precision)\n","    model_dict[id]['metrics']['recall'].append(metrics.recall)\n","    model_dict[id]['metrics']['f1'].append(metrics.f1)\n","    model_dict[id]['metrics']['power'].append(metrics.power)\n","    model_dict[id]['metrics']['type1'].append(metrics.type1)\n","    model_dict[id]['metrics']['type2'].append(1 - metrics.power)\n","\n","aggregate_data = []\n","for id in model_dict:\n","  # Aggregate mean metrics (accuracy, power, type 1 error) for each model ID\n","  aggregate_data.append([id, np.mean(model_dict[id]['metrics']['acc']), np.mean(model_dict[id]['metrics']['power']), np.mean(model_dict[id]['metrics']['type1'])])\n","\n","import pandas as pd\n","\n","df = pd.DataFrame(aggregate_data, columns=[\"Code\", \"Accuracy\", \"Power\", \"Type 1\"])\n","\n","# Extract features (Scale, CNS, IA, IMP) from the model's format code for analysis\n","df[\"Scale\"] = df[\"Code\"].str[0].astype(int)\n","df[\"CNS\"] = df[\"Code\"].str[1].astype(int)\n","df[\"IA\"] = df[\"Code\"].str[2].astype(int)\n","df[\"IMP\"] = df[\"Code\"].str[3].astype(int)\n","\n","print()\n","# Analyze the impact of 'Scale', 'CNS', and 'IA' features on Accuracy\n","for feature in [\"Scale\", \"CNS\", \"IA\"]:\n","    mean_with = df[df[feature] == 1][\"Accuracy\"].mean()\n","    mean_without = df[df[feature] == 0][\"Accuracy\"].mean()\n","    print(f\"{feature}: {mean_with:.4f} (enabled) vs {mean_without:.4f} (disabled) | diff={mean_with - mean_without:.4f}\")\n","\n","# Analyze the impact of different imputation types ('MEAN', 'MEDIAN', 'IQM') on Accuracy\n","mean_with_mean = df[df[\"IMP\"] == 1][\"Accuracy\"].mean()\n","mean_with_median = df[df[\"IMP\"] == 2][\"Accuracy\"].mean()\n","mean_with_iqm = df[df[\"IMP\"] == 3][\"Accuracy\"].mean()\n","mean_without = df[df[\"IMP\"] == 0][\"Accuracy\"].mean()\n","print()\n","print('___IMP___')\n","print(f'MEAN: {mean_with_mean:.4f} (enabled) vs {mean_without:.4f} (IMP disabled) | diff={mean_with_mean - mean_without:.4f}')\n","print(f'MEDIAN: {mean_with_median:.4f} (enabled) vs {mean_without:.4f} (IMP disabled) | diff={mean_with_median - mean_without:.4f}')\n","print(f'IQM: {mean_with_iqm:.4f} (enabled) vs {mean_without:.4f} (IMP disabled) | diff={mean_with_iqm - mean_without:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bgeug2E55T7z"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nyOMnUZ_MFUY"},"outputs":[],"source":["top_3_accuracy_codes = df.nlargest(3, 'Accuracy')['Code'].tolist()\n","print(top_3_accuracy_codes)"]},{"cell_type":"markdown","metadata":{"id":"xYYTVs3DDrlT"},"source":["## Power By Effect Size Plotting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3m0PblZfBDWG"},"outputs":[],"source":["model_ids_to_plot = ['0011', '0012', '1010']\n","\n","fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n","fig.suptitle('Power by Effect Size for Selected Models', fontsize=16)\n","\n","for i, id in enumerate(model_ids_to_plot):\n","  dataset_it, labels_it, format = process(dataset.copy(), labels, model_dict[id]['format'])\n","  # Assuming we want to plot metrics for the first model in the list for each ID\n","  model = model_dict[id]['models'][0]\n","  metrics = compute_metrics(model, dataset_it, labels_it, effect_sizes)\n","\n","  bins = list(metrics.metrics_by_power.keys())\n","  bins.remove('undiff')\n","\n","  power_by_bin = [metrics.metrics_by_power[bin]['power'] for bin in bins]\n","  n_by_bin = [metrics.metrics_by_power[bin]['n'] for bin in bins]\n","\n","  # Replace NaN values with 0 for plotting\n","  power_by_bin = [0 if np.isnan(x) else x for x in power_by_bin]\n","\n","  # Create new x-axis labels\n","  new_bins = []\n","  for j in range(len(bins)):\n","      if j < len(bins) - 1:\n","          new_bins.append(f\"[{bins[j]}, {bins[j+1]})\")\n","      else:\n","          new_bins.append(f\"[{bins[j]}, inf)\")\n","\n","  # Use indices for plotting positions\n","  x_positions = np.arange(len(bins))\n","\n","  # Plot Power on the current subplot\n","  axs[i].grid(True, axis='y', alpha=0.5, zorder=0, linestyle=':')\n","  bars_power = axs[i].bar(x_positions, power_by_bin, color='grey')\n","  axs[i].set_title(f'Model {id} Power')\n","  axs[i].set_xlabel('Effect Size Bin')\n","  axs[i].set_ylabel('Power')\n","  axs[i].set_xticks(x_positions)\n","  axs[i].set_xticklabels(new_bins, rotation=45, ha='right')\n","  axs[i].set_ylim(0, 1.1)\n","  for bar, n in zip(bars_power, n_by_bin):\n","      yval = bar.get_height()\n","      axs[i].text(bar.get_x() + bar.get_width()/2, yval + 0.01, n, ha='center', va='bottom')\n","\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent suptitle overlap\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YPBP6pqz42A0"},"source":["## Create Ratings Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmV03IzS41eg"},"outputs":[],"source":["ratings = {}\n","for id in model_dict:\n","  model_index = np.argmax(model_dict[id]['metrics']['acc'])\n","  model = model_dict[id]['models'][model_index]\n","  dataset_it, labels_it, format = process(dataset.copy(), labels.copy(), model_dict[id]['format'])\n","  preds = create_ratings(model, dataset_it, labels_it)\n","  ratings[id] = preds"]},{"cell_type":"markdown","metadata":{"id":"XaShQ2yc2MsN"},"source":["## Variance Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owZ7-AGTl3Ie"},"outputs":[],"source":["accuracy = []\n","power = []\n","type1 = []\n","x_labels = []\n","for id in ['0012', '0011', '1010']:\n","  accuracy.append(model_dict[id]['metrics']['acc'])\n","  power.append(model_dict[id]['metrics']['power'])\n","  type1.append(model_dict[id]['metrics']['type1'])\n","  x_labels.append(id)\n","\n","fig, axs = plt.subplots(1, 3, figsize=(12, 4))  # 1 row, 3 columns\n","\n","# Plot individual box plots\n","axs[0].boxplot(accuracy, labels=x_labels)\n","axs[0].set_title('Accuracy')\n","axs[0].grid(True, linestyle=\"--\", alpha=0.5)\n","\n","axs[1].boxplot(power, labels=x_labels)\n","axs[1].set_title('Power')\n","axs[1].grid(True, linestyle=\"--\", alpha=0.5)\n","\n","axs[2].boxplot(type1, labels=x_labels)\n","axs[2].set_title('Type 1')\n","axs[2].grid(True, linestyle=\"--\", alpha=0.5)"]},{"cell_type":"markdown","metadata":{"id":"rNAdbGK9J3x9"},"source":["# LOOCV"]},{"cell_type":"markdown","metadata":{"id":"VV22dBEwJI1r"},"source":["### LOOCV Fine Tune Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYNngfgZPMUZ"},"outputs":[],"source":["# Create the \"LOOCV\" directory if it doesn't exist\n","loocv_dir = \"LOOCV\"\n","os.makedirs(loocv_dir, exist_ok=True)\n","json_file_path = os.path.join(loocv_dir, \"loocv_metrics_ft.json\")\n","\n","if 'loocv_metrics_ft.json' in os.listdir(loocv_dir):\n","  with open(json_file_path, 'r') as f:\n","      loocv_metrics_ft = json.load(f)\n","else:\n","  loocv_metrics_ft = {}\n","\n","itterations = 5\n","for id in ['0012', '0011', '1010']:\n","  if id not in loocv_metrics_ft:\n","    loocv_metrics_ft[id] = {'acc': [],\n","                        'power': [],\n","                        'type1': [],\n","                        }\n","\n","  runs_complete = len(loocv_metrics_ft[id]['acc'])\n","  for run in range(itterations - runs_complete):\n","\n","    random.seed(42 + 7 * (run + runs_complete))\n","    np.random.seed(42 + 7 * (run + runs_complete))\n","    tf.random.set_seed(42 + 7 * (run + runs_complete))\n","\n","    best_model = int(np.argmax(model_dict[id]['metrics']['acc']))\n","    model = model_dict[id]['models'][best_model]\n","    preds = np.array([])\n","    print(id, '_____')\n","    for n in range(len(labels)):\n","      if n % 10 == 0:\n","        print(f'{n}|', end='')\n","      dataset_it, labels_it, format = process(dataset.copy(), labels.copy(), model_dict[id]['format'])\n","      if labels_it.shape[0] == labels.shape[0]:\n","        test_one = np.array([dataset_it[n]])\n","        test_one_lbl = np.array([labels_it[n]])\n","        one_out = np.delete(dataset_it, n, axis=0)\n","        one_out_lbls = np.delete(labels_it, n, axis=0)\n","      else:\n","        indices = range(n*3, n*3 + 3, 1)\n","        test_one = dataset_it[indices]\n","        test_one_lbl = labels_it[indices]\n","        one_out = np.delete(dataset_it, indices, axis=0)\n","        one_out_lbls = np.delete(labels_it, indices, axis=0)\n","\n","      history = model.fit(\n","          one_out,\n","          one_out_lbls,\n","          epochs=100,\n","          validation_data=(test_one, test_one_lbl),\n","          verbose=0)\n","\n","      pred = np.argmax(model.predict(test_one, verbose=0), axis=-1)\n","      preds = np.concatenate((preds, pred.flatten()), axis=0)\n","\n","    correct_lbl = labels.flatten()\n","    true = preds == correct_lbl\n","    TP = np.sum(true * correct_lbl)\n","    TN = np.sum(true * (1 - correct_lbl))\n","    FP = np.sum((1 - true) * (1 - correct_lbl))\n","    FN = np.sum((1 - true) * correct_lbl)\n","    acc = (TP + TN) / (TP + TN + FP + FN)\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    f1 = 2 * precision * recall / (precision + recall)\n","    power = TP / (TP + FN)\n","    type1 = FP / (FP + TN)\n","\n","    loocv_metrics_ft[id]['acc'].append(acc)\n","    loocv_metrics_ft[id]['power'].append(power)\n","    loocv_metrics_ft[id]['type1'].append(type1)\n","\n","    with open(json_file_path, \"w\") as json_file:\n","      json.dump(loocv_metrics_ft, json_file)\n","\n","    print(f'Run {run} Accuracy: {acc}, Power: {power}, Type 1: {type1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Zu5BsMzikoU"},"outputs":[],"source":["acc_bin = []\n","power_bin = []\n","type1_bin = []\n","for id in loocv_metrics_ft:\n","  acc = np.mean(loocv_metrics_ft[id]['acc'])\n","  power = np.mean(loocv_metrics_ft[id]['power'])\n","  type1 = np.mean(loocv_metrics_ft[id]['type1'])\n","\n","  acc_bin.append(loocv_metrics_ft[id]['acc'])\n","  power_bin.append(loocv_metrics_ft[id]['power'])\n","  type1_bin.append(loocv_metrics_ft[id]['type1'])\n","\n","  print(f'{id}: Accuracy: {acc:.3f}, Power: {power:.3f}, Type 1: {type1:.3f}')\n","\n","plt.boxplot(acc_bin, tick_labels=loocv_metrics_ft.keys())\n","plt.title('LOOCV Accuracy')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()\n","plt.boxplot(power_bin, tick_labels=loocv_metrics_ft.keys())\n","plt.title('LOOCV Power')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()\n","plt.boxplot(type1_bin, tick_labels=loocv_metrics_ft.keys())\n","plt.title('LOOCV Type 1')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CQxyk6p2LDg4"},"source":["## LOOCV Train Models From Blank"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gj-hMiwIlevO"},"outputs":[],"source":["predictions_bl = {}\n","\n","# Create the \"LOOCV\" directory if it doesn't exist\n","loocv_dir = \"LOOCV\"\n","os.makedirs(loocv_dir, exist_ok=True)\n","json_file_path = os.path.join(loocv_dir, \"loocv_metrics_bl.json\")\n","\n","if 'loocv_metrics_bl.json' in os.listdir(loocv_dir):\n","  with open(json_file_path, 'r') as f:\n","      loocv_metrics_bl = json.load(f)\n","else:\n","  loocv_metrics_bl = {}\n","\n","itterations = 5\n","for id in ['0012', '0011', '1010']:\n","  print(id, '_____')\n","  if id not in loocv_metrics_bl:\n","    loocv_metrics_bl[id] = {'acc': [],\n","                        'power': [],\n","                        'type1': [],\n","                        }\n","  predictions_bl[id] = {}\n","\n","  runs_complete = len(loocv_metrics_bl[id]['acc'])\n","  for run in range(itterations - runs_complete):\n","    random.seed(42 + 7 * (run + runs_complete))\n","    np.random.seed(42 + 7 * (run + runs_complete))\n","    tf.random.set_seed(42 + 7 * (run + runs_complete))\n","    model = build_model(model_dict[id]['format'])\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    preds = np.array([])\n","    for n in range(len(labels)):\n","      if n % 10 == 0:\n","        print(f'{n}|', end='')\n","      dataset_it, labels_it, format = process(dataset.copy(), labels.copy(), model_dict[id]['format'])\n","      if labels_it.shape[0] == labels.shape[0]:\n","        test_one = np.array([dataset_it[n]])\n","        test_one_lbl = np.array([labels_it[n]])\n","        one_out = np.delete(dataset_it, n, axis=0)\n","        one_out_lbls = np.delete(labels_it, n, axis=0)\n","      else:\n","        indices = range(n*3, n*3 + 3, 1)\n","        test_one = dataset_it[indices]\n","        test_one_lbl = labels_it[indices]\n","        one_out = np.delete(dataset_it, indices, axis=0)\n","        one_out_lbls = np.delete(labels_it, indices, axis=0)\n","\n","      equalized_epochs = 100 + int(model_dict[id]['epochs'][0])\n","      history = model.fit(\n","          one_out,\n","          one_out_lbls,\n","          epochs=equalized_epochs,\n","          validation_data=(test_one, test_one_lbl),\n","          verbose=0)\n","\n","      pred = np.argmax(model.predict(test_one, verbose=0), axis=-1)\n","      preds = np.concatenate((preds, pred.flatten()), axis=0)\n","\n","    correct_lbl = labels.flatten()\n","    true = preds == correct_lbl\n","    TP = np.sum(true * correct_lbl)\n","    TN = np.sum(true * (1 - correct_lbl))\n","    FP = np.sum((1 - true) * (1 - correct_lbl))\n","    FN = np.sum((1 - true) * correct_lbl)\n","    acc = (TP + TN) / (TP + TN + FP + FN)\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    f1 = 2 * precision * recall / (precision + recall)\n","    power = TP / (TP + FN)\n","    type1 = FP / (FP + TN)\n","\n","    predictions_bl[id][run] = [acc, preds]\n","\n","    loocv_metrics_bl[id]['acc'].append(acc)\n","    loocv_metrics_bl[id]['power'].append(power)\n","    loocv_metrics_bl[id]['type1'].append(type1)\n","\n","    with open(json_file_path, \"w\") as json_file:\n","      json.dump(loocv_metrics_bl, json_file)\n","\n","    print(f'Run {run} Accuracy: {acc}, Power: {power}, Type 1: {type1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"769XL9fGZLT7"},"outputs":[],"source":["acc_bin = []\n","power_bin = []\n","type1_bin = []\n","for id in loocv_metrics_bl:\n","  acc = np.mean(loocv_metrics_bl[id]['acc'])\n","  power = np.mean(loocv_metrics_bl[id]['power'])\n","  type1 = np.mean(loocv_metrics_bl[id]['type1'])\n","\n","  acc_bin.append(loocv_metrics_bl[id]['acc'])\n","  power_bin.append(loocv_metrics_bl[id]['power'])\n","  type1_bin.append(loocv_metrics_bl[id]['type1'])\n","\n","  print(f'{id}: Accuracy: {acc:.3f}, Power: {power:.3f}, Type 1: {type1:.3f}')\n","\n","plt.boxplot(acc_bin, tick_labels=loocv_metrics_bl.keys())\n","plt.title('LOOCV Accuracy')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()\n","plt.boxplot(power_bin, tick_labels=loocv_metrics_bl.keys())\n","plt.title('LOOCV Power')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()\n","plt.boxplot(type1_bin, tick_labels=loocv_metrics_bl.keys())\n","plt.title('LOOCV Type 1')\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uISRJd3GSQBA"},"source":["### Create Rating Set"]},{"cell_type":"code","source":["max_run = [0, None, None]\n","for id in predictions_bl:\n","  for run in predictions_bl[id]:\n","    if predictions_bl[id][run][0] > max_run[0]:\n","      max_run = [predictions_bl[id][run][0], id, run]\n","\n","print(max_run)\n","\n","ratings[f'LOOCV_Trained_{max_run[1]}'] = predictions_bl[max_run[1]][max_run[2]][1]"],"metadata":{"id":"8GE4chNHx3Zr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ae9o13KS3r5P"},"source":["## Combine LOOCV Boxplots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJ40m5RE3t_-"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Example data: Three models, each with three techniques\n","data = {\n","    \"0011\": {\n","        \"Tech 1\": model_dict['0011']['metrics']['acc'],\n","        \"Tech 2\": loocv_metrics_bl['0011']['acc'],\n","        \"Tech 3\": loocv_metrics_ft['0011']['acc'],\n","    },\n","    \"0012\": {\n","        \"Tech 1\": model_dict['0012']['metrics']['acc'],\n","        \"Tech 2\": loocv_metrics_bl['0012']['acc'],\n","        \"Tech 3\": loocv_metrics_ft['0012']['acc'],\n","    },\n","    \"1010\": {\n","        \"Tech 1\": model_dict['1010']['metrics']['acc'],\n","        \"Tech 2\": loocv_metrics_bl['1010']['acc'],\n","        \"Tech 3\": loocv_metrics_ft['1010']['acc'],\n","    }\n","}\n","\n","# Flatten data for plotting\n","all_data = []\n","positions = []\n","offset = [-0.2, 0, 0.2]  # Offset for techniques within a model\n","xticks = []\n","tick_positions = []\n","\n","for i, (model, techniques) in enumerate(data.items()):\n","    xticks.append(model)\n","    tick_positions.append(i)\n","    for j, (tech, values) in enumerate(techniques.items()):\n","        all_data.append(values)\n","        positions.append(i + offset[j])  # Spread techniques slightly\n","\n","colors = [\"lightgray\", \"gray\", \"dimgray\"]\n","colors = [plt.cm.Greys(x) for x in [0.1, 0.4, 0.7]]\n","tech_names = ['Train w/ Simulated', 'LOOCV w/ Real', 'LOOCV Fine-Tune w/ Real']\n","\n","for j, tech in enumerate(techniques):\n","    tech_data = [data[model][tech] for model in xticks]\n","    positions = [i + offset[j] for i in tick_positions]\n","\n","    bp = plt.boxplot(\n","        tech_data,\n","        positions=positions,\n","        widths=0.15,\n","        patch_artist=True  # Required to color the boxes\n","    )\n","\n","    # Apply consistent color\n","    for box in bp['boxes']:\n","        box.set_facecolor(colors[j])\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(colors[j])\n","    for cap in bp['caps']:\n","        cap.set_color(colors[j])\n","    for median in bp['medians']:\n","        median.set_color(\"black\")  # Optional: black median line\n","\n","     # Set whisker, cap, median, and flier colors for visibility\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(\"black\")\n","    for cap in bp['caps']:\n","        cap.set_color(\"black\")\n","    for median in bp['medians']:\n","        median.set_color(\"black\")\n","    for flier in bp['fliers']:\n","        flier.set(marker='o', color='black')\n","\n","# Labeling\n","plt.xticks(tick_positions, xticks)\n","plt.xlabel(\"Models\")\n","plt.ylabel(\"Metric\")\n","#plt.title(\"Comparison of Accuracy Across Models\")\n","plt.grid(axis='y', linestyle=\"--\", alpha=0.5) # Add gridlines on the y-axis\n","plt.ylim(0.8, 1) # Increase y-axis limit\n","plt.yticks(np.arange(0.8, 1, 0.05)) # Set y-axis ticks at intervals of 0.2\n","\n","\n","# Legend handles\n","from matplotlib.patches import Patch\n","legend_handles = [Patch(facecolor=colors[i], label=tech_names[i]) for i, t in enumerate(techniques)]\n","plt.legend(handles=legend_handles, loc=\"lower left\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnasNqpm4xge"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Example data: Three models, each with three techniques\n","data = {\n","    \"0011\": {\n","        \"Tech 1\": model_dict['0011']['metrics']['power'],\n","        \"Tech 2\": loocv_metrics_bl['0011']['power'],\n","        \"Tech 3\": loocv_metrics_ft['0011']['power'],\n","    },\n","    \"0012\": {\n","        \"Tech 1\": model_dict['0012']['metrics']['power'],\n","        \"Tech 2\": loocv_metrics_bl['0012']['power'],\n","        \"Tech 3\": loocv_metrics_ft['0012']['power'],\n","    },\n","    \"1010\": {\n","        \"Tech 1\": model_dict['1010']['metrics']['power'],\n","        \"Tech 2\": loocv_metrics_bl['1010']['power'],\n","        \"Tech 3\": loocv_metrics_ft['1010']['power'],\n","    }\n","}\n","\n","# Flatten data for plotting (prepare data structure for box plot)\n","all_data = []\n","positions = []\n","offset = [-0.2, 0, 0.2]  # Offset for techniques within a model to avoid overlap\n","xticks = []\n","tick_positions = []\n","\n","for i, (model, techniques) in enumerate(data.items()):\n","    xticks.append(model)\n","    tick_positions.append(i)\n","    for j, (tech, values) in enumerate(techniques.items()):\n","        all_data.append(values)\n","        positions.append(i + offset[j])  # Spread techniques slightly for visualization\n","\n","# Define colors and labels for the different techniques/bars\n","colors = [\"lightgray\", \"gray\", \"dimgray\"]\n","colors = [plt.cm.Greys(x) for x in [0.1, 0.4, 0.7]]\n","tech_names = ['Train w/ Simulated', 'LOOCV w/ Real', 'LOOCV Fine-Tune w/ Real']\n","\n","# Loop through each technique to plot its data for all models\n","for j, tech in enumerate(techniques):\n","    tech_data = [data[model][tech] for model in xticks]\n","    positions = [i + offset[j] for i in tick_positions]\n","\n","    # Create box plots for the current technique across models\n","    bp = plt.boxplot(\n","        tech_data,\n","        positions=positions,\n","        widths=0.15,\n","        patch_artist=True  # Required to color the boxes\n","    )\n","\n","    # Apply consistent color to the box plot elements\n","    for box in bp['boxes']:\n","        box.set_facecolor(colors[j])\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(colors[j])\n","    for cap in bp['caps']:\n","        cap.set_color(colors[j])\n","    for median in bp['medians']:\n","        median.set_color(\"black\")  # Optional: black median line\n","\n","     # Set whisker, cap, median, and flier colors for visibility\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(\"black\")\n","    for cap in bp['caps']:\n","        cap.set_color(\"black\")\n","    for median in bp['medians']:\n","        median.set_color(\"black\")\n","    for flier in bp['fliers']:\n","        flier.set(marker='o', color='black')\n","\n","# Labeling and plot customization\n","plt.xticks(tick_positions, xticks)\n","plt.xlabel(\"Models\")\n","plt.ylabel(\"Metric\")\n","#plt.title(\"Comparison of Type 1 Error Across Models\")\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.ylim(0.8, 1) # Increase y-axis limit\n","plt.yticks(np.arange(0.8, 1, 0.05)) # Set y-axis ticks at intervals of 0.2\n","\n","# Create legend handles and display the legend\n","from matplotlib.patches import Patch\n","legend_handles = [Patch(facecolor=colors[i], label=tech_names[i]) for i, t in enumerate(techniques)]\n","plt.legend(handles=legend_handles, loc=\"lower left\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWPtqWWC5OqU"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Example data: Three models, each with three techniques\n","# This dictionary structures the data for three specific models ('0011', '0012', '1010'),\n","# with each model having performance metrics ('type1' in this case) from three different techniques.\n","data = {\n","    \"0011\": {\n","        \"Tech 1\": model_dict['0011']['metrics']['type1'],\n","        \"Tech 2\": loocv_metrics_bl['0011']['type1'],\n","        \"Tech 3\": loocv_metrics_ft['0011']['type1'],\n","    },\n","    \"0012\": {\n","        \"Tech 1\": model_dict['0012']['metrics']['type1'],\n","        \"Tech 2\": loocv_metrics_bl['0012']['type1'],\n","        \"Tech 3\": loocv_metrics_ft['0012']['type1'],\n","    },\n","    \"1010\": {\n","        \"Tech 1\": model_dict['1010']['metrics']['type1'],\n","        \"Tech 2\": loocv_metrics_bl['1010']['type1'],\n","        \"Tech 3\": loocv_metrics_ft['1010']['type1'],\n","    }\n","}\n","\n","# Prepare data structure for plotting box plots\n","# These lists will hold all the data points, their positions on the x-axis,\n","# and the labels for the x-axis ticks.\n","all_data = []\n","positions = []\n","offset = [-0.2, 0, 0.2]  # Offset for techniques within a model to avoid overlap\n","xticks = []\n","tick_positions = []\n","\n","# Populate the x-axis labels and positions based on the models\n","for i, (model, techniques) in enumerate(data.items()):\n","    xticks.append(model)\n","    tick_positions.append(i)\n","    for j, (tech, values) in enumerate(techniques.items()):\n","        all_data.append(values)\n","        positions.append(i + offset[j])  # Spread techniques slightly for visualization\n","\n","# Define colors and labels for the different techniques/bars in the legend\n","colors = [\"lightgray\", \"gray\", \"dimgray\"]\n","colors = [plt.cm.Greys(x) for x in [0.1, 0.4, 0.7]]\n","tech_names = ['Train w/ Simulated', 'LOOCV w/ Real', 'LOOCV Fine-Tune w/ Real']\n","\n","# Loop through each technique to plot its data for all models\n","# This creates grouped box plots, one group per model, with boxes for each technique.\n","for j, tech in enumerate(techniques):\n","    tech_data = [data[model][tech] for model in xticks]\n","    positions = [i + offset[j] for i in tick_positions]\n","\n","    # Create box plots for the current technique across models\n","    bp = plt.boxplot(\n","        tech_data,\n","        positions=positions,\n","        widths=0.15,\n","        patch_artist=True  # Required to color the boxes\n","    )\n","\n","    # Apply consistent color to the box plot elements (boxes, whiskers, caps, medians)\n","    for box in bp['boxes']:\n","        box.set_facecolor(colors[j])\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(colors[j])\n","    for cap in bp['caps']:\n","        cap.set_color(colors[j])\n","    for median in bp['medians']:\n","        median.set_color(\"black\")  # Optional: black median line\n","\n","     # Set whisker, cap, median, and flier colors for visibility\n","    for whisker in bp['whiskers']:\n","        whisker.set_color(\"black\")\n","    for cap in bp['caps']:\n","        cap.set_color(\"black\")\n","    for median in bp['medians']:\n","        median.set_color(\"black\")\n","    for flier in bp['fliers']:\n","        flier.set(marker='o', color='black')\n","\n","# Labeling and plot customization\n","plt.xticks(tick_positions, xticks) # Set x-axis tick labels\n","plt.xlabel(\"Models\") # Label for the x-axis\n","plt.ylabel(\"Metric\") # Label for the y-axis\n","#plt.title(\"Comparison of Accuracy Across Models\") # Optional title for the plot\n","plt.grid(True, linestyle=\"--\", alpha=0.5) # Add gridlines on the y-axis\n","\n","# Create legend handles and display the legend\n","from matplotlib.patches import Patch\n","legend_handles = [Patch(facecolor=colors[i], label=tech_names[i]) for i, t in enumerate(techniques)]\n","plt.legend(handles=legend_handles, loc=\"lower left\") # Place the legend on the plot\n","\n","plt.show() # Display the plot"]},{"cell_type":"markdown","metadata":{"id":"Gy5mdKM93VX2"},"source":["# Interrater Agreement"]},{"cell_type":"markdown","metadata":{"id":"mMcywc2voBv2"},"source":["## Load Expert Ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWaoNl_h0JVL"},"outputs":[],"source":["def load_expert_ratings(file_path, subs):\n","\n","    if 'r-' in file_path:\n","      i = 1\n","    elif 'rh-' in file_path:\n","      i = 0\n","\n","    results = []\n","\n","    with open(file_path, 'r') as file:\n","        for _ in range(4):\n","              next(file, None)\n","        for line in file:\n","            # Split the line into columns\n","            columns = line.strip().split(',')  # Assuming CSV format\n","\n","            # Check if we have enough columns and column 2 contains a subject from our list\n","            if len(columns) >= 5 and int(columns[i]) in subs:\n","                subject = int(columns[i])\n","                # Extract values from columns 2, 3, and 4 (indices 1, 2, 3)\n","                col3_value = int(columns[1+i])\n","                col4_value = int(columns[2+i])\n","                col5_value = int(columns[3+i])\n","\n","                # Add the values to our results list\n","                results += [col3_value, col4_value, col5_value]\n","\n","    return np.array(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkMt2Mr1n_ia"},"outputs":[],"source":["r_val_subs = [2,3,4,133,136,140,13,14,16,18,20,22,23,25,26,156,28,30,31,158,34,36,38,46,50,52,54,56,57,58,61,69,70,72,74,76,79,80,82,101,102,104,105,106]\n","h_val_subs = [6,10,11,12,13,16,17,18,20,23,26,27,28,29,30,33,34,35,36,37,38,39,40,41,42,43,44,45,47,49,54,55,57,58,61,62,63,64,65]\n","r_val_subs = sorted(r_val_subs)\n","h_val_subs = sorted(h_val_subs)\n","file_names = os.listdir('Ratings')\n","\n","r_ratings = []\n","h_ratings = []\n","for name in file_names:\n","  if 'rh-' in name and '.csv' in name:\n","    h_ratings.append(name)\n","  elif 'r-' in name and '.csv' in name:\n","    r_ratings.append(name)\n","\n","for name in r_ratings:\n","  rater = name.split('-')[1].split('.')[0]\n","  if rater == 'neely_VA':\n","    rater = 'Expert_1'\n","  elif rater == 'katie_VA':\n","    rater = 'Expert_2'\n","  elif rater == 'CDC':\n","    rater = 'MDC'\n","  ratings[rater] = load_expert_ratings(os.path.join('Ratings', name), r_val_subs)\n","\n","for name in h_ratings:\n","  rater = name.split('-')[1].split('.')[0]\n","  if rater == 'neely_VA':\n","    rater = 'Expert_1'\n","  elif rater == 'katie_VA':\n","    rater = 'Expert_2'\n","  elif rater == 'CDC':\n","    rater = 'MDC'\n","  ratings[rater] = np.concatenate((ratings[rater], load_expert_ratings(os.path.join('Ratings', name), h_val_subs)))\n","\n","ratings['Ground_Truth'] = labels.flatten()"]},{"cell_type":"markdown","metadata":{"id":"ocdgz3MC9321"},"source":["## Create IRA Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saT84Ox1906W"},"outputs":[],"source":["keys = ['Ground_Truth', 'Expert_1', 'Expert_2', 'MDC', '1010', '0011', '0012', 'LOOCV_Trained_0012']\n","\n","cm = [[-1 for j in range(len(keys))] for i in range(len(keys))]\n","for i, key1 in enumerate(keys):\n","  for j, key2 in enumerate(keys):\n","    agreement = np.mean(ratings[key1] == ratings[key2])\n","    cm[i][j] = agreement\n","\n","cm = np.array(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLkoSRnw_AI3"},"outputs":[],"source":["import seaborn as sns\n","\n","plt.figure(figsize=(10, 8))\n","\n","# Create mask for the diagonal (self-comparison values)\n","mask = np.triu(np.ones_like(cm, dtype=bool))\n","np.fill_diagonal(mask, True)\n","\n","# Set up the heatmap\n","sns.heatmap(cm, annot=True, fmt='.2f', cmap='coolwarm',\n","            xticklabels=keys, yticklabels=keys,\n","            vmin=0.8, vmax=1, mask=mask)\n","\n","# Add labels and title\n","plt.xlabel('Rater')\n","plt.ylabel('Rater')\n","\n","# Rotate x-axis labels for better readability\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()"]},{"cell_type":"markdown","source":["# Describe the Curated Dataset"],"metadata":{"id":"ka4cV26nBf7o"}},{"cell_type":"code","source":["data = {\n","    \"Descriptor\": [\"Level for Diff\", \"Level for Undiff\", \"Trend (deg)\", \"Trend (SMD/Sesh)\", \"Variability\", \"CV\"],\n","    10: [0, 0, 0, 0, 0, 0],\n","    50: [0, 0, 0, 0, 0, 0],\n","    90: [0, 0, 0, 0, 0, 0],\n","}\n","\n","df = pd.DataFrame(data)"],"metadata":{"id":"2XeznhTvB1VY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["format = Format()\n","format.scale = 0\n","format.cns = 1\n","format.ia = 1\n","format.imp = 0\n","# Process the dataset to get Centralized and Individualized data for calculating various descriptors\n","dataset_it, labels_it, format = process(dataset.copy(), labels.copy(), format)\n","labels_it = labels_it.flatten()\n","\n","# Calculate and store percentiles for 'Level for Diff' (Differentiated) series\n","dataset_temp = []\n","for line in dataset_it[labels_it == 1]:\n","  series = [y for y in line if y != -1]\n","  if len(series) == 0:\n","    continue\n","  dataset_temp.append(np.mean(series))\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"Level for Diff\", p] = float(np.percentile(dataset_temp, p))\n","\n","# Calculate and store percentiles for 'Level for Undiff' (Undifferentiated) series\n","dataset_temp = []\n","for line in dataset_it[labels_it == 0]:\n","  series = [y for y in line if y != -1]\n","  if len(series) == 0:\n","    continue\n","  dataset_temp.append(np.mean(series))\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"Level for Undiff\", p] = np.percentile(dataset_temp, p)\n","\n","# Calculate and store percentiles for 'Trend (SMD/Sesh)' (Standardized Mean Difference per Session)\n","dataset_temp = []\n","for line in dataset_it:\n","  series = [y for y in line if y != -1]\n","  if len(series) == 0:\n","    continue\n","  a, b = np.polyfit(range(len(series)), series, 1)\n","  dataset_temp.append(a)\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"Trend (SMD/Sesh)\", p] = np.percentile(dataset_temp, p)\n","\n","# Calculate and store percentiles for 'Variability' (Standard Deviation of residuals after linear fit)\n","dataset_temp = []\n","for line in dataset_it:\n","  series = [y for y in line if y != -1]\n","  if len(series) == 0:\n","    continue\n","  a, b = np.polyfit(range(len(series)), series, 1)\n","  error = [y - a*x + b for x, y in enumerate(series)]\n","  dataset_temp.append(np.std(error))\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"Variability\", p] = np.percentile(dataset_temp, p)\n","\n","# Calculate and store percentiles for 'CV' (Coefficient of Variation)\n","dataset_temp = []\n","for line in dataset_it:\n","  series = [y for y in line if y != -1]\n","  if len(series) == 0:\n","    continue\n","  std = np.std(series).clip(epsilon, None)\n","  dataset_temp.append(abs(np.mean(series)) / std)\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"CV\", p] = np.percentile(dataset_temp, p)\n","\n","format = Format()\n","format.scale = 0\n","format.cns = 0\n","format.ia = 1\n","format.imp = 0\n","# Reprocess the dataset with a different format to calculate trend in degrees\n","dataset_it, labels_it, format = process(dataset.copy(), labels.copy(), format)\n","labels_it = labels_it.flatten()\n","\n","# Calculate and store percentiles for 'Trend (deg)' (Trend in degrees based on the first series)\n","dataset_temp = []\n","for line in dataset_it:\n","  series = [y for y in line[1] if y != -1]\n","  if len(series) == 0:\n","    continue\n","  a, b = np.polyfit(range(len(series)), series, 1)\n","  dataset_temp.append(degrees(atan(a)))\n","for p in [10, 50, 90]:\n","  df.loc[df[\"Descriptor\"] == \"Trend (deg)\", p] = np.percentile(dataset_temp, p)"],"metadata":{"id":"RxaTWwEnDsGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df)"],"metadata":{"id":"6KaVJ8z_FQty"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["UfEESgR_mIhQ","rNAdbGK9J3x9","ae9o13KS3r5P"],"provenance":[{"file_id":"1K_rqbJ2jy01Cem3OxR5ZyHODisZ1rVj5","timestamp":1762966674252},{"file_id":"1fvQq5f7Kd8IEWfBPrWBqJ_A2cNSYApY7","timestamp":1753313979582}],"authorship_tag":"ABX9TyOy8uezLyW5KLscJIJVF5k2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}